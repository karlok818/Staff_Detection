{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_EK66ereQhl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve all the masks wore types images\n",
    "masks_folders_names = os.listdir(\"data\")\n",
    "imgFileName = []\n",
    "width = []\n",
    "height = []\n",
    "croppedResizedGrayImg = []\n",
    "targetClass = []\n",
    "\n",
    "for masks_folder_name in masks_folders_names:\n",
    "    print(masks_folder_name)\n",
    "    for fname in os.listdir(\"data\\\\\" + masks_folder_name):        \n",
    "        img = cv2.imread(os.path.join(\"data\", masks_folder_name, fname))\n",
    "        imgFileName.append(fname)\n",
    "        width.append(img.shape[1])\n",
    "        height.append(img.shape[0])\n",
    "        # convert image to grayscale, crop, and resize\n",
    "        croppedResizedGrayImg.append(cv2.cvtColor(cv2.resize(np.asarray(tf.image.central_crop(img, central_fraction=0.5)), (256, 256)), cv2.COLOR_BGR2GRAY))\n",
    "        targetClass.append(masks_folder_name)\n",
    "        # print(fname)\n",
    "\n",
    "data = pd.DataFrame({'imgfileName': imgFileName, 'width': width, 'height': height, 'croppedResizedGrayImg': croppedResizedGrayImg, 'targetClass': targetClass})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the samples in Mask Correctly Worn and Mask Not Worn classes through flipping\n",
    "rotatedGrayImg = []\n",
    "targetClass = []\n",
    "for i in range(0, len(data)):\n",
    "    img = data.loc[i, 'croppedResizedGrayImg']\n",
    "    rotatedGrayImg.append(cv2.flip(img, 0))\n",
    "    rotatedGrayImg.append(cv2.flip(img, 1))\n",
    "    rotatedGrayImg.append(cv2.flip(img, -1))\n",
    "    targetClass.append(data.loc[i, 'targetClass'])\n",
    "    targetClass.append(data.loc[i, 'targetClass'])\n",
    "    targetClass.append(data.loc[i, 'targetClass'])\n",
    "\n",
    "augmt_data = pd.DataFrame({'imgfileName': None, 'width': 0, 'height': 0, 'croppedResizedGrayImg': rotatedGrayImg, 'targetClass': targetClass})\n",
    "data = data.append(augmt_data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.imgfileName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.loc[data['imgfileName'] == 'tag21.JPG', 'croppedResizedGrayImg'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 2-D image to 1-D \n",
    "flattenImg = []\n",
    "for img in data['croppedResizedGrayImg']:\n",
    "    flattenImg.append(img.flatten())\n",
    "\n",
    "dataset = pd.DataFrame(flattenImg)\n",
    "dataset['targetClass'] = data['targetClass'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# seperate the data to independent variables and target variable\n",
    "x = dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, -1]\n",
    "\n",
    "# scale and perform kernel PCA for dimensions reduction\n",
    "scaler = MinMaxScaler().fit(x)\n",
    "x = scaler.transform(x)\n",
    "x = pd.DataFrame(x)\n",
    "kpca = KernelPCA(kernel='rbf', fit_inverse_transform=True, gamma=10)\n",
    "kpca_fit = kpca.fit(x)\n",
    "x = kpca_fit.transform(x)\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "# set K-fold as 10 and shuffle the data\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# initialize models\n",
    "models = {\n",
    "    'SVC' : svm.SVC(kernel='linear'),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1score', 'trained time']\n",
    "models_performance = {model: {metric: [] for metric in metrics} for model in models.keys()}\n",
    "\n",
    "for model_type, model_obj in models.items():\n",
    "    print(model_type)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        # partition the data to train and test sets based on each k-fold partition\n",
    "        x_train, x_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # fit the model with training data\n",
    "        start_time = time.time()\n",
    "        model_obj.fit(x_train, y_train)\n",
    "        models_performance[model_type]['trained time'].append(time.time() - start_time) \n",
    "\n",
    "        # predict on the testing data\n",
    "        y_pred = model_obj.predict(x_test)\n",
    "\n",
    "        # store the accuracy store at each fold iteration\n",
    "        models_performance[model_type]['accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        models_performance[model_type]['precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        models_performance[model_type]['recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        models_performance[model_type]['f1score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "        print(confusion_matrix(y_test, y_pred, labels=[0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the overall performance score of the models (average the scores obtained in each k-fold iteration)\n",
    "from statistics import mean \n",
    "\n",
    "models_overall_performance = {model: {metric: None for metric in metrics} for model in models.keys()}\n",
    "\n",
    "for model_type, metrics_dict in models_performance.items():\n",
    "    for metric_type, metric_scores in metrics_dict.items():\n",
    "        if metric_type != 'trained time':\n",
    "            models_overall_performance[model_type][metric_type] = round(mean(metric_scores), 3)\n",
    "        else:\n",
    "            models_overall_performance[model_type][metric_type] = str(round(sum(metric_scores), 2)) + ' seconds'\n",
    "    \n",
    "\n",
    "models_overall_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x, y)\n",
    "\n",
    "with open('tag_detector_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the YOLO model\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')  # Replace with the appropriate YOLO model files\n",
    "\n",
    "# Set the target classes\n",
    "target_classes = ['person']  # Only detect people\n",
    "\n",
    "# Load the tag detector model\n",
    "tag_detector_model = pickle.load(open('tag_detector_model.pkl', 'rb'))  # Replace with your trained tag detector model\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'sample_trim2.mp4'  # Replace with your input video file path\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frame rate of the video\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the segment duration in seconds\n",
    "segment_duration = 1\n",
    "\n",
    "# Calculate the number of frames per segment\n",
    "segment_frames = int(fps * segment_duration)\n",
    "\n",
    "# Initialize variables for storing the results\n",
    "person_regions = []\n",
    "tag_detections = []\n",
    "\n",
    "# Process each segment of the video\n",
    "while True:\n",
    "    # Read the segment frames\n",
    "    frames = []\n",
    "    for _ in range(segment_frames):\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        break\n",
    "    \n",
    "    # Perform person detection and tag detection on each frame\n",
    "    for frame in frames:\n",
    "        # Construct a blob from the input frame\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "        # Set the input blob for the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Perform forward pass and get the output layer names\n",
    "        output_layers = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers)\n",
    "\n",
    "        # Initialize lists for detected person bounding boxes and confidences\n",
    "        person_boxes = []\n",
    "        person_confidences = []\n",
    "\n",
    "        # Loop over the outputs of each layer\n",
    "        for output in layer_outputs:\n",
    "            # Loop over each detection\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if class_id == 0 and confidence > 0.5:  # Check if the detection is a person with confidence threshold\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    width = int(detection[2] * frame.shape[1])\n",
    "                    height = int(detection[3] * frame.shape[0])\n",
    "\n",
    "                    x = int(center_x - width/2)\n",
    "                    y = int(center_y - height/2)\n",
    "\n",
    "                    person_boxes.append([x, y, width, height])\n",
    "                    person_confidences.append(float(confidence))\n",
    "\n",
    "        # Apply non-maximum suppression to eliminate overlapping bounding boxes\n",
    "        indices = cv2.dnn.NMSBoxes(person_boxes, person_confidences, score_threshold=0.5, nms_threshold=0.5)\n",
    "\n",
    "        # Loop over the remaining person detections\n",
    "        for i in indices:\n",
    "            # i = i[0]\n",
    "            x, y, w, h = person_boxes[i]\n",
    "\n",
    "            # Extract the person region from the frame\n",
    "            person_region = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Perform tag detection on the person region\n",
    "            if person_region is not None:\n",
    "\n",
    "                try:\n",
    "                    # Resize the person region to match the input size of the tag detector model\n",
    "                    resized_person_region = cv2.cvtColor(cv2.resize(person_region, (256, 256)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Flatten the resized person region\n",
    "                    flattened_person_region = resized_person_region.flatten()\n",
    "\n",
    "                    # Pass the flattened person region through the tag detector model\n",
    "                    tag_predictions = tag_detector_model.predict([flattened_person_region])\n",
    "\n",
    "                    # Assuming the tag detector model outputs a binary classification (with tag or without tag)\n",
    "                    is_staff_with_tag = tag_predictions > 0.5  # Adjust the threshold as needed\n",
    "\n",
    "                    if is_staff_with_tag:\n",
    "                        # Save the frame with the bounding box and xy coordinates\n",
    "                        output_frame = frame.copy()\n",
    "                        cv2.rectangle(output_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        label = f'Person {person_confidences[i]:.2f} | (x:{x}, y:{y})'\n",
    "                        cv2.putText(output_frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                        cv2.imwrite(f'frame_with_tag_{len(person_regions)}.png', output_frame)\n",
    "\n",
    "                    # Store the person region and tag detection result\n",
    "                    person_regions.append(person_region)\n",
    "                    tag_detections.append(is_staff_with_tag)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # Display the frames or perform any other desired operations\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and close any open windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 3_ HowToMngData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
